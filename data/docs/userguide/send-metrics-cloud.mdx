---
date: 2024-06-06
id: send-metrics-cloud
title: Send Metrics to SigNoz Cloud
---

import GetHelp from '@/components/shared/get-help.md'
import SaveChangesRestart from '@/components/shared/save-changes-and-restart.md'

This document contains instructions on how to send metrics from various sources to SigNoz Cloud using OpenTelemetry Collector and view your metrics in SigNoz.

## Requirements

- OpenTelemetry Collector v0.60.0 or newer
- Network access to `ingest.{region}.signoz.cloud:443`
- Valid SigNoz Cloud ingestion key

## Methods to Send Metrics

There are multiple ways to send metrics to SigNoz Cloud:

1. **From your application using custom metrics**
2. **From OpenTelemetry Collector** (Infrastructure and third-party services)
3. **From Kubernetes using Prometheus receiver**

## Send Custom Metrics from Applications

### Step 1. Install OpenTelemetry SDK

For Python applications:
```bash
pip install opentelemetry-api
pip install opentelemetry-sdk
pip install opentelemetry-exporter-otlp
```

### Step 2. Create and send custom metrics

```python
from opentelemetry import metrics
from opentelemetry.exporter.otlp.proto.grpc.metric_exporter import OTLPMetricExporter
from opentelemetry.sdk.metrics import MeterProvider
from opentelemetry.sdk.metrics.export import PeriodicExportingMetricReader

# Configure the metric exporter
exporter = OTLPMetricExporter(
    endpoint="https://ingest.<region>.signoz.cloud:443",
    headers={"signoz-ingestion-key": "<your-ingestion-key>"}
)

# Set up the meter provider
reader = PeriodicExportingMetricReader(exporter, export_interval_millis=30000)
metrics.set_meter_provider(MeterProvider(metric_readers=[reader]))

# Create a meter
meter = metrics.get_meter("my.application")

# Create custom metrics
request_counter = meter.create_counter(
    name="http_requests_total",
    description="Total number of HTTP requests",
    unit="1"
)

response_time_histogram = meter.create_histogram(
    name="http_request_duration_seconds",
    description="HTTP request duration in seconds",
    unit="s"
)

# Use the metrics in your application
request_counter.add(1, {"method": "GET", "endpoint": "/api/users"})
response_time_histogram.record(0.250, {"method": "GET", "status": "200"})
```

### Step 3. Validate custom metrics

- Replace `<region>` with your SigNoz Cloud [region](https://signoz.io/docs/ingestion/signoz-cloud/overview/#endpoint)
- Replace `<your-ingestion-key>` with your SigNoz [ingestion key](https://signoz.io/docs/ingestion/signoz-cloud/keys/)
- Your metrics will appear in **Metrics Explorer** in SigNoz UI

## Send Metrics via OpenTelemetry Collector

### From VMs or Docker

#### Step 1. Configure the OpenTelemetry Collector

Create `otel-collector-config.yaml`:

```yaml
receivers:
  otlp:
    protocols:
      grpc:
        endpoint: localhost:4317
      http:
        endpoint: localhost:4318
  
  hostmetrics:
    collection_interval: 30s
    scrapers:
      cpu: {}
      disk: {}
      load: {}
      filesystem: {}
      memory: {}
      network: {}

processors:
  batch:
    send_batch_size: 1000
    timeout: 10s
  
  resourcedetection:
    detectors: [env, system]
    timeout: 2s

exporters:
  otlp:
    endpoint: "ingest.<region>.signoz.cloud:443"
    tls:
      insecure: false
    headers:
      "signoz-ingestion-key": "<your-ingestion-key>"

service:
  pipelines:
    metrics:
      receivers: [otlp]
      processors: [batch]
      exporters: [otlp]
    metrics/hostmetrics:
      receivers: [hostmetrics]
      processors: [resourcedetection, batch]
      exporters: [otlp]
```

#### Step 2. Run the collector

```bash
./otelcol --config=otel-collector-config.yaml
```

### From Kubernetes using Prometheus Receiver

#### Step 1. Configure Prometheus receiver for K8s metrics

Create `k8s-otel-collector-config.yaml`:

```yaml
receivers:
  prometheus:
    config:
      scrape_configs:
        # Kubernetes API server metrics
        - job_name: 'kubernetes-apiservers'
          kubernetes_sd_configs:
            - role: endpoints
          scheme: https
          tls_config:
            ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
          bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
          relabel_configs:
            - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
              action: keep
              regex: default;kubernetes;https
        
        # Kubelet metrics
        - job_name: 'kubernetes-nodes'
          scheme: https
          tls_config:
            ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
          bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
          kubernetes_sd_configs:
            - role: node
          relabel_configs:
            - action: labelmap
              regex: __meta_kubernetes_node_label_(.+)
            - target_label: __address__
              replacement: kubernetes.default.svc:443
            - source_labels: [__meta_kubernetes_node_name]
              regex: (.+)
              target_label: __metrics_path__
              replacement: /api/v1/nodes/${1}/proxy/metrics
        
        # Pod metrics
        - job_name: 'kubernetes-pods'
          kubernetes_sd_configs:
            - role: pod
          relabel_configs:
            - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
              action: keep
              regex: true
            - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
              action: replace
              target_label: __metrics_path__
              regex: (.+)

processors:
  batch:
    send_batch_size: 1000
    timeout: 10s
  
  k8sattributes:
    extract:
      metadata:
        - k8s.pod.name
        - k8s.pod.uid
        - k8s.deployment.name
        - k8s.namespace.name
        - k8s.node.name
        - k8s.pod.start_time

exporters:
  otlp:
    endpoint: "ingest.<region>.signoz.cloud:443"
    tls:
      insecure: false
    headers:
      "signoz-ingestion-key": "<your-ingestion-key>"

service:
  pipelines:
    metrics:
      receivers: [prometheus]
      processors: [k8sattributes, batch]
      exporters: [otlp]
```

#### Step 2. Deploy as DaemonSet

Create `k8s-otel-collector.yaml`:

```yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: otel-collector
  namespace: signoz
spec:
  selector:
    matchLabels:
      name: otel-collector
  template:
    metadata:
      labels:
        name: otel-collector
    spec:
      serviceAccount: otel-collector
      containers:
      - name: otel-collector
        image: otel/opentelemetry-collector-contrib:latest
        args: ["--config=/etc/config/config.yaml"]
        volumeMounts:
        - name: config
          mountPath: /etc/config
        env:
        - name: KUBE_NODE_NAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
      volumes:
      - name: config
        configMap:
          name: otel-collector-config
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: otel-collector
  namespace: signoz
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: otel-collector
rules:
- apiGroups: [""]
  resources: ["nodes", "nodes/proxy", "services", "endpoints", "pods"]
  verbs: ["get", "list", "watch"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: otel-collector
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: otel-collector
subjects:
- kind: ServiceAccount
  name: otel-collector
  namespace: signoz
```

#### Step 3. Deploy to Kubernetes

```bash
# Create namespace
kubectl create namespace signoz

# Create ConfigMap with collector config
kubectl create configmap otel-collector-config \
  --from-file=config.yaml=k8s-otel-collector-config.yaml \
  -n signoz

# Deploy the collector
kubectl apply -f k8s-otel-collector.yaml
```

## Enable Specific Metric Receivers

### Database Metrics

#### MySQL
```yaml
receivers:
  mysql:
    endpoint: localhost:3306
    username: monitoring_user
    password: ${MYSQL_PASSWORD}
    database: mysql
    collection_interval: 30s
```

#### PostgreSQL
```yaml
receivers:
  postgresql:
    endpoint: localhost:5432
    username: monitoring_user
    password: ${POSTGRES_PASSWORD}
    databases: ["postgres"]
    collection_interval: 30s
```

#### Redis
```yaml
receivers:
  redis:
    endpoint: localhost:6379
    collection_interval: 30s
```

### Message Queue Metrics

#### RabbitMQ
```yaml
receivers:
  rabbitmq:
    endpoint: http://localhost:15672
    username: ${RABBITMQ_USERNAME}
    password: ${RABBITMQ_PASSWORD}
    collection_interval: 30s
```

Add these receivers to your pipeline:
```yaml
service:
  pipelines:
    metrics/databases:
      receivers: [mysql, postgresql, redis]
      processors: [batch]
      exporters: [otlp]
```

## Viewing Metrics in SigNoz

Once your metrics are being sent to SigNoz Cloud, you can view and analyze them using:

### Metrics Explorer
- Navigate to **Metrics Explorer** in the SigNoz UI
- Search and filter metrics by name, labels, or time range
- Create visualizations with different chart types
- Apply aggregations and functions to your metrics data

### Creating Dashboards
- Use metrics in [custom dashboards](/docs/userguide/manage-dashboards/)
- Create panels with time-series, gauges, and other visualizations
- Set up alerts based on metric thresholds

## Validating Metrics Integration

To verify that your metrics are being sent correctly:

1. **Check Metrics Explorer**: Your metrics should appear in the Metrics Explorer within a few minutes
2. **Verify in Dashboards**: Navigate to dashboards to see if host/application metrics are visible
3. **Check Collector Logs**: Review collector logs for any export errors
4. **Use SigNoz Troubleshoot Tool**:
   ```bash
   curl -sL https://github.com/SigNoz/troubleshoot/raw/main/scripts/install.sh | bash
   ./troubleshoot checkEndpoint --endpoint=ingest.<region>.signoz.cloud:443
   ```

## Troubleshooting

### Metrics not appearing in SigNoz

1. **Check ingestion key and region**: Verify your configuration matches your SigNoz Cloud account
2. **Verify network connectivity**: Ensure your collector can reach `ingest.<region>.signoz.cloud:443`
3. **Review collector logs**: Look for authentication or export errors
4. **Check receiver configuration**: Ensure receivers are properly configured and data sources are accessible

### Custom metrics not showing

1. **Verify instrumentation**: Ensure your application is properly instrumented with OpenTelemetry
2. **Check metric names**: Verify metric names follow OpenTelemetry naming conventions
3. **Review export intervals**: Custom metrics may take time to appear based on export intervals

### Kubernetes metrics missing

1. **Check RBAC permissions**: Ensure service account has proper cluster access
2. **Verify Prometheus annotations**: Ensure pods are properly annotated for scraping
3. **Review scrape configs**: Check that scrape configurations match your cluster setup

## Sample Applications

- [Python custom metrics example](https://github.com/SigNoz/sample-apps/tree/main/python-metrics)
- [Node.js metrics instrumentation](https://github.com/SigNoz/sample-apps/tree/main/nodejs-metrics)
- [Kubernetes monitoring setup](https://github.com/SigNoz/sample-apps/tree/main/k8s-metrics)

## Related Videos

- [How to view Prometheus Metrics in SigNoz](https://youtu.be/QGJYNYzfM9o)

## Get Help

<GetHelp />