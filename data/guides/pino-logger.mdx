---
title: "Pino Logger: Complete Guide to Fast Node.js Logging (2025) - Installation, Configuration & Best Practices"
slug: "pino-logger-complete-guide-nodejs"
date: "2025-07-23"
tags: [pino, nodejs, logging, performance, structured-logging, json-logs, observability]
authors: [signoz-team]
description: "Master Pino logger for Node.js development. Complete 2025 guide covering installation, configuration, performance optimization, and production deployment with examples and best practices."
keywords: [pino logger, nodejs logging, structured logging, json logs, performance logging, fast logging, pino configuration, nodejs observability, logging best practices]
---

When building Node.js applications, you need logging that won't slow down your system. Traditional loggers like Winston and Bunyan offer rich features but often introduce performance bottlenecks that can hurt application responsiveness. Pino delivers up to 10x better performance than alternatives while maintaining the features you need for production environments.

This guide covers implementing Pino in your Node.js applications, mastering configuration options, optimizing for production, and integrating with observability platforms. Whether you're running high-throughput APIs or resource-constrained microservices, you'll learn to leverage Pino's full potential.

## What is Pino Logger?

Pino is a fast Node.js logger designed for production applications where performance matters. Created by Matteo Collina at NearForm, Pino prioritizes speed through specific architectural choices:

- **Minimal overhead**: Zero-cost abstractions and pre-serialized message queuing
- **JSON-only output**: Structured logging enforced for machine readability  
- **Asynchronous processing**: Worker threads and buffered I/O
- **Child logger support**: Context propagation without metadata duplication

### Performance Comparison

Benchmarks consistently show Pino's performance advantage:

| Library | Throughput (ops/sec) | Memory Usage (MB) | CPU Overhead |
|---------|---------------------|------------------|--------------|
| **Pino** | 50,000+ | 25 | 3.1% |
| Winston | 10,000 | 140 | 11% |
| Bunyan | 8,500 | 91 | 8.2% |

*Based on 10,000 log operations under load*

## Installation and Setup

### Basic Installation

```bash
npm install pino
# Development pretty printing
npm install pino-pretty --save-dev
```

### First Steps

```javascript
const pino = require('pino');

// Basic logger
const logger = pino();
logger.info('Hello World');
// {"level":30,"time":1674123456789,"pid":12345,"hostname":"myserver","msg":"Hello World"}

// Development-friendly output
const devLogger = pino({ 
  transport: { target: 'pino-pretty' } 
});
devLogger.info('Development log');
// [16:30:56.789] INFO: Development log
```

### Framework Integration

**Express.js:**

```javascript
const express = require('express');
const pino = require('pino');
const pinoHttp = require('pino-http');

const app = express();
const logger = pino();

app.use(pinoHttp({ logger }));

app.get('/', (req, res) => {
  req.log.info('Processing request');
  res.json({ message: 'Hello World' });
});
```

**Fastify (built-in support):**

```javascript
const fastify = require('fastify')({
  logger: {
    level: 'info',
    transport: { target: 'pino-pretty' }
  }
});

fastify.get('/', async (request, reply) => {
  request.log.info('Handling request');
  return { hello: 'world' };
});
```

## Configuration Guide

### Log Levels

```javascript
const logger = pino({ level: 'info' });

logger.trace('Trace message');  // Won't output (below threshold)
logger.debug('Debug message');  // Won't output (below threshold) 
logger.info('Info message');    // Will output
logger.warn('Warning message'); // Will output
logger.error('Error message');  // Will output
logger.fatal('Fatal message');  // Will output
```

### Advanced Configuration

```javascript
const logger = pino({
  level: process.env.LOG_LEVEL || 'info',
  
  // Custom timestamp
  timestamp: () => `,"time":"${new Date().toISOString()}"`,
  
  // Format output
  formatters: {
    bindings: (bindings) => ({
      pid: bindings.pid,
      hostname: bindings.hostname,
      service: 'my-api'
    }),
    level: (label) => ({ severity: label.toUpperCase() })
  },
  
  // Redact sensitive fields
  redact: {
    paths: ['password', 'email', 'creditCard'],
    censor: '**REDACTED**'
  }
});
```

### Environment-Specific Setup

```javascript
const createLogger = () => {
  const baseConfig = {
    level: process.env.LOG_LEVEL || 'info',
    formatters: {
      bindings: () => ({
        pid: process.pid,
        hostname: require('os').hostname()
      })
    }
  };

  if (process.env.NODE_ENV === 'development') {
    return pino({
      ...baseConfig,
      transport: {
        target: 'pino-pretty',
        options: {
          colorize: true,
          translateTime: 'SYS:standard'
        }
      }
    });
  }

  // Production config
  return pino({
    ...baseConfig,
    transport: {
      target: 'pino/file',
      options: {
        destination: './logs/app.log',
        sync: false
      }
    }
  });
};
```

## Serializers and Advanced Features

### Built-in Serializers

Pino provides optimized serializers for common data types:

```javascript
const logger = pino({
  serializers: {
    err: pino.stdSerializers.err,
    req: pino.stdSerializers.req,
    res: pino.stdSerializers.res
  }
});

// Error serialization
try {
  throw new Error('Something went wrong');
} catch (err) {
  logger.error({ err }, 'Request failed');
}
// Includes: type, message, stack

// HTTP request serialization  
app.use((req, res, next) => {
  logger.info({ req }, 'Incoming request');
  next();
});
// Includes: method, url, headers, remoteAddress
```

### Custom Serializers

```javascript
const logger = pino({
  serializers: {
    user: (user) => ({
      id: user.id,
      name: user.name,
      // Redact sensitive data
      email: user.email ? `${user.email.split('@')[0]}***@***` : undefined
    }),
    
    payment: (payment) => ({
      amount: payment.amount,
      currency: payment.currency,
      cardNumber: '****'  // Never log sensitive payment data
    })
  }
});

logger.info({
  user: { id: 1, name: 'John', email: 'john@example.com' },
  payment: { amount: 100, currency: 'USD', cardNumber: '1234567890' }
}, 'Payment processed');
```

### Child Loggers for Context

Child loggers add context without repeating metadata:

```javascript
const logger = pino();

// Request context middleware
app.use((req, res, next) => {
  req.log = logger.child({
    requestId: crypto.randomUUID(),
    userId: req.user?.id,
    method: req.method,
    path: req.path
  });
  next();
});

// Use throughout request lifecycle
app.get('/api/users/:id', async (req, res) => {
  req.log.info('Fetching user');
  
  try {
    const user = await getUserById(req.params.id);
    req.log.info({ user: user.id }, 'User fetched');
    res.json(user);
  } catch (error) {
    req.log.error({ err: error }, 'Failed to fetch user');
    res.status(500).json({ error: 'Internal server error' });
  }
});
```

## Performance Optimization

### Asynchronous Logging

Prevent I/O operations from blocking the main thread:

```javascript
const logger = pino({
  transport: {
    target: 'pino/file',
    options: {
      destination: './logs/app.log',
      sync: false,        // Enable async mode
      minLength: 4096,    // Buffer size before flush
      mkdir: true
    }
  }
});
```

### Worker Thread Transports

Maximum performance with worker threads:

```javascript
const logger = pino({
  transport: {
    targets: [
      {
        target: 'pino/file',
        options: { destination: './logs/app.log' },
        level: 'info'
      },
      {
        target: 'pino/file', 
        options: { destination: './logs/error.log' },
        level: 'error'
      }
    ]
  }
});
```

### Extreme Mode

When ultimate performance is required:

```javascript
const logger = pino(pino.extreme('./logs/app.log'));

// Ensure logs flush before exit
process.on('SIGINT', () => {
  logger.flush();
  process.exit(0);
});
```

## Production Configuration

### Complete Production Setup

```javascript
const pino = require('pino');
const path = require('path');

const createProductionLogger = () => {
  return pino({
    level: process.env.LOG_LEVEL || 'info',
    
    // Service metadata
    base: {
      service: process.env.SERVICE_NAME || 'api',
      version: process.env.SERVICE_VERSION || '1.0.0',
      environment: process.env.NODE_ENV || 'production'
    },
    
    timestamp: pino.stdTimeFunctions.isoTime,
    
    formatters: {
      level: (label) => ({ level: label }),
      bindings: (bindings) => ({
        pid: bindings.pid,
        host: bindings.hostname
      })
    },
    
    // Redact sensitive data
    redact: {
      paths: [
        'password', 'token', 'apiKey', 'authorization', 'cookie',
        'req.headers.authorization', 'req.headers.cookie'
      ],
      censor: '[REDACTED]'
    },
    
    serializers: {
      err: pino.stdSerializers.err,
      req: pino.stdSerializers.req,
      res: pino.stdSerializers.res
    },
    
    transport: {
      targets: [
        {
          target: 'pino/file',
          options: {
            destination: path.join(process.cwd(), 'logs', 'app.log'),
            sync: false,
            mkdir: true
          },
          level: 'info'
        },
        {
          target: 'pino/file',
          options: {
            destination: path.join(process.cwd(), 'logs', 'error.log'),
            sync: false,
            mkdir: true
          },
          level: 'error'
        }
      ]
    }
  });
};
```

### Error Handling Best Practices

```javascript
const handleError = (error, context = {}) => {
  logger.error({
    err: error,
    ...context,
    errorId: crypto.randomUUID()
  }, 'Unhandled error occurred');
};

// Global error handlers
process.on('uncaughtException', (error) => {
  handleError(error, { type: 'uncaughtException' });
  process.exit(1);
});

process.on('unhandledRejection', (reason, promise) => {
  handleError(reason, { 
    type: 'unhandledRejection',
    promise: promise.toString()
  });
});
```

## Observability Platform Integration

### OpenTelemetry Integration

```javascript
const logger = pino({
  transport: {
    targets: [
      {
        target: 'pino-opentelemetry-transport',
        options: {
          resourceAttributes: {
            'service.name': 'my-node-service',
            'service.version': '1.0.0'
          }
        }
      },
      {
        target: 'pino-pretty',
        options: { colorize: true }
      }
    ]
  }
});
```

### ELK Stack Integration

```javascript
const logger = pino({
  transport: {
    target: 'pino-elasticsearch',
    options: {
      node: 'http://localhost:9200',
      index: 'logs',
      consistency: 'one',
      auth: {
        username: 'elastic',
        password: 'password'
      }
    }
  }
});
```

## Common Issues and Solutions

### Error Serialization

**Problem**: Error objects don't serialize completely.

**Solution**: Use the error serializer pattern:

```javascript
// Incorrect - loses stack trace
logger.error(error, 'Something went wrong');

// Correct - preserves error information  
logger.error({ err: error }, 'Something went wrong');
```

### Stream Configuration

**Problem**: Confusion about sync vs async modes.

**Solution**: Understand the trade-offs:

```javascript
// Synchronous - blocks main thread but ensures writes
const syncLogger = pino(pino.destination({ sync: true }));

// Asynchronous - better performance, potential data loss on crashes
const asyncLogger = pino(pino.destination({ sync: false }));

// Extreme mode - maximum performance with manual flushing
const extremeLogger = pino(pino.extreme());
process.on('SIGINT', () => extremeLogger.flush());
```

### Message and Object Parameters

**Problem**: Wrong parameter ordering.

**Solution**: Follow the correct pattern:

```javascript
// Incorrect - payload might be ignored
logger.info('User logged in', { userId: 123 });

// Correct - object first, message second
logger.info({ userId: 123 }, 'User logged in');
```

## Performance Best Practices

### Minimize Object Creation

```javascript
// Pre-create objects when possible
const baseContext = { service: 'auth', version: '1.0' };
const contextLogger = logger.child(baseContext);

// Use conditional logging for expensive operations
if (logger.level === 'trace') {
  logger.trace({ complexObject }, 'Detailed operation info');
}
```

### Batch Operations

```javascript
const processUsers = async (users) => {
  const startTime = Date.now();
  let processed = 0;
  let errors = 0;
  
  for (const user of users) {
    try {
      await processUser(user);
      processed++;
    } catch (error) {
      errors++;
      logger.warn({ userId: user.id, err: error }, 'User processing failed');
    }
  }
  
  logger.info({
    operation: 'bulk_user_process',
    processed,
    errors,
    duration: Date.now() - startTime
  }, 'Bulk processing completed');
};
```

## Migration from Other Loggers

### Winston to Pino

```javascript
// Winston
const winston = require('winston');
const logger = winston.createLogger({
  level: 'info',
  format: winston.format.json(),
  transports: [
    new winston.transports.File({ filename: 'error.log', level: 'error' }),
    new winston.transports.File({ filename: 'combined.log' })
  ]
});

// Pino equivalent
const logger = pino({
  level: 'info',
  transport: {
    targets: [
      { target: 'pino/file', options: { destination: 'error.log' }, level: 'error' },
      { target: 'pino/file', options: { destination: 'combined.log' } }
    ]
  }
});
```

### Migration Considerations

- **Log Format**: Pino always outputs JSON - adjust log parsing accordingly
- **Error Serialization**: Use `{ err: error }` pattern instead of passing error directly  
- **Child Loggers**: Pino's child logger pattern is more efficient
- **Transports**: Move from Winston transports to Pino's worker thread system

## Monitoring and Health Checks

### Health Check Logging

```javascript
const healthLogger = logger.child({ component: 'health' });

const checkHealth = async () => {
  const checks = {
    database: await checkDatabase(),
    redis: await checkRedis(),
    external_api: await checkExternalAPI()
  };

  const allHealthy = Object.values(checks).every(check => check.healthy);
  
  healthLogger[allHealthy ? 'info' : 'error']({
    checks,
    overall: allHealthy ? 'healthy' : 'unhealthy'
  }, 'Health check completed');
  
  return { healthy: allHealthy, checks };
};
```

### Performance Metrics

```javascript
const trackOperation = async (operationName, operation) => {
  const start = process.hrtime.bigint();
  
  try {
    const result = await operation();
    const duration = Number(process.hrtime.bigint() - start) / 1000000;
    
    logger.info({
      operation: operationName,
      duration,
      status: 'success'
    }, 'Operation completed');
    
    return result;
  } catch (error) {
    const duration = Number(process.hrtime.bigint() - start) / 1000000;
    
    logger.error({
      operation: operationName,
      duration,
      status: 'error',
      err: error
    }, 'Operation failed');
    
    throw error;
  }
};
```

## Get Started with SigNoz

SigNoz provides comprehensive Node.js logging integration specifically designed for structured JSON logs from Pino. The platform offers unified observability where your Pino logs correlate with distributed tracing and metrics for complete application monitoring. SigNoz includes a powerful logs dashboard with robust querying capabilities, allowing you to filter by service name, log level, request ID, or custom attributes for precise troubleshooting.

The integration supports both Winston and Pino through OpenTelemetry transports, enabling you to send structured logs with contextual data like request IDs, HTTP methods, paths, and error stacks. You can visualize logs alongside traces in flamegraphs and Gantt charts, monitor application latency and error rates in real-time, and set up alerting for critical log patterns.

You can choose between various deployment options in SigNoz. The easiest way to get started with SigNoz is [SigNoz cloud](https://signoz.io/teams/). We offer a 30-day free trial account with access to all features. 

Those who have data privacy concerns and can't send their data outside their infrastructure can sign up for either [enterprise self-hosted or BYOC offering](https://signoz.io/contact-us/).

Those who have the expertise to manage SigNoz themselves or just want to start with a free self-hosted option can use our [community edition](https://signoz.io/docs/install/self-host/).

Hope we answered all your questions regarding Pino logger implementation. If you have more questions, feel free to use the SigNoz AI chatbot, or join our [slack community](https://signoz.io/slack/).

## Key Takeaways

Pino delivers exceptional performance for Node.js logging through its JSON-first architecture, asynchronous processing, and minimal overhead design. The logger consistently outperforms alternatives by 5-10x in throughput while providing production-ready features like serializers, data redaction, and child loggers.

Essential implementation points:

- **Performance advantage**: Significant throughput improvements over Winston and Bunyan
- **Production features**: Built-in serializers, sensitive data redaction, and worker thread transports  
- **Observability integration**: Seamless compatibility with modern platforms like SigNoz, ELK, and Grafana
- **Developer experience**: Clear APIs and comprehensive configuration options

Start with basic Pino configuration, progressively adopt advanced features like custom serializers and worker thread transports, then integrate with your observability platform for comprehensive application monitoring. Whether you're running microservices, APIs, or serverless functions, Pino provides the logging foundation needed to scale efficiently while maintaining operational visibility.